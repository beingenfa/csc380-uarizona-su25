{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce1eee1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    " As a last step before you submit, Please restart the notebook, rerun all cells, save and then submit.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29f5a4",
   "metadata": {},
   "source": [
    "# Homework 7 : Linear / Nonlinear Classification ( 90 Points )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4b1d7",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "\n",
    "This homework will study 3-class classification in  the famous \"Iris\" dataset.  The dataset was introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems\" as an example of linear discriminant analysis. The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear classifier to distinguish the species from each other. We will do the same using classifiers that we have learned.\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65239d16",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    "* Each subproblem is worth 10 points.\n",
    "\n",
    "* The notebook is structured with clearly marked cells where you should insert your code.\n",
    "\n",
    "* Please complete all cells as instructed to ensure full credit.\n",
    "\n",
    "* Do not remove or rearrange any cells.\n",
    "\n",
    "* Before you submit, restart the notebook, rerun all cells, save and then submit.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339796b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from sklearn import datasets\n",
    "\n",
    "# Data manipluation and viz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data processing \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model Training\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba020e",
   "metadata": {},
   "source": [
    "## Problem 1 : Getting Started with the Data ( 40 points )\n",
    "\n",
    "### (a) Load Dataset ( 10 points)\n",
    "\n",
    "Because this dataset is so well-known, Scikit-Learn includes a special function for loading it, which is provided below.  In the cells below:\n",
    "  * Load the data and create a Train / Test split with 25% test data (train_test_split() function)\n",
    "  * For the above, make sure to use the provided random state so that results are repeatable\n",
    "  * Display the training inputs (you can use function display())\n",
    "\n",
    "Note: You will need the feature names later on.  It is helpful at this point to store them in a set using the DataFrame.colums property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bfb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this random state for train/test split\n",
    "random_state=1234\n",
    "\n",
    "iris = datasets.load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Insert code to Load the data and create a Train / Test split with 25% test data (train_test_split() function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b69525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to view the training data inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab183980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to Display the target/output labels from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c4487",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1612b8",
   "metadata": {},
   "source": [
    "### (b) Analyzing Feature Distributions via Density Plots (10 points) \n",
    "\n",
    "Now we will explore our feature distributions.  In the cell below, use the Pandas DataFrame plot feature to plot the density of each feature in the training data.  Make sure your plots are clearly labeled, including axes and a title if appropriate.\n",
    "\n",
    "[ Documentation - Pandas - DataFrame.plot ](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here to plot the features—either all at once in a single cell, or one at a time using multiple cells. Choose whichever is preferred for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c452c93",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93effa",
   "metadata": {},
   "source": [
    "### (c) Boxplot of Feature Distributions (10 points)\n",
    "\n",
    "Sometimes it is better to look at distributions of each feature plotted together.  In the cell below produce a boxplot (use plt.boxplot()) of each feature in the training data.  **Make sure to rotate X-tick labels 45-degrees so they are readable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe5c4d",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9445cee6",
   "metadata": {},
   "source": [
    "### (d) Feature Pair Scatterplots with Correlation Coefficients ( 10 points )\n",
    "\n",
    "Now let's see how well we can separate classes from each pair of features.  In the cell below produce a scatterplot of **every pair of features** in the training data.  There will be 6 scatterplots in all.  Make sure to follow these instructions:\n",
    "  * Color each marker red, green, or blue depending on the true class label\n",
    "  * Use numpy.corrcoef to compute the correlation coefficient of each feature\n",
    "  * Title each plot with the correlation coefficient\n",
    "  * Label each axis using the corresponding feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ebbd1",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5b468",
   "metadata": {},
   "source": [
    "## Problem 2 : Train a logistic regression classifier ( 30 points )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42522e87",
   "metadata": {},
   "source": [
    "### (a) Feature Selection Using LogisticRegressionCV ( 10 points )\n",
    "\n",
    "Now we will look at finding the best feature out of all the features. To do this, you will preform Cross Validation of Logustic Regression. We will break this into subproblems to walk through it. In this section,do the following:\n",
    "* Using LogisticRegressionCV perform 5-fold cross validation to train on each feature\n",
    "* For each run use Matplotlib errorbar() to plot the average +/- standard deviation of error versus regularization coefficient (the property LogisticRegressionCV.Cs_) -- there should be 4 plots in total\n",
    "* Set plot X-label with the feature name, and Y-label \"Accuracy\"\n",
    "* Title each plot with the maximum achieved accuracy score\n",
    "* Report the best accuracy from cross-validation\n",
    "* Finally, report the best performing feature and save it for later\n",
    "\n",
    "Make sure to set the following properties in LogisticRegressionCV:\n",
    "* cv=5\n",
    "* max_iter=1e4\n",
    "* random_state=0\n",
    "* multi_class='multinomial'\n",
    "* Cs=10\n",
    "\n",
    "[Documentation - Scikit-Learn - LogisticRegressionCV](https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8996b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here for \n",
    "# using LogisticRegressionCV to perform 5-fold cross validation to train on each feature\n",
    "# Loop over each feature individually and perform cross-validation training.\n",
    "# Store results (accuracies and standard deviations) in variables/dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f53af10",
   "metadata": {},
   "source": [
    "**Plots** (4/10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting average +/- standard deviation of error versus regularization coefficient \n",
    "\n",
    "# Label axes and add titles with max accuracy.\n",
    "# This can be one cell per feature (4 cells total) or all plots in one cell — whichever you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d169924",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature = \"YOUR SOLUTION\"\n",
    "best_accuracy = 100\n",
    "print(f\"The best accuracy from cross-validation is for the feature {best_feature} with accuracy of {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced1aef",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a49114",
   "metadata": {},
   "source": [
    "### (b) Visualizing Decision Boundaries for Classifier ( 10 points )\n",
    "\n",
    "Now lets look at all pairs of features.  The cell below provides a function plotLogreg2feat() to visualize the learned classifier for a pair of features.  This function will draw the decision boundaries for each of the three classes, which will give us a better picture of what's going on.  In the cell below that do the following:\n",
    "* Loop over every pair of features (there are 6 pairs total)\n",
    "* Using LogisticRegressionCV perform 5-fold cross validation to train a classifier on the pair of features\n",
    "* Make sure to use **the same cross validation options as the previous experiment**\n",
    "* Using plotLogreg2feat plot the learned classifier\n",
    "* Title each plot with the maximum average accuracy from cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLogreg2feat(X, featname_1, featname_2, model):\n",
    "    '''\n",
    "    INPUTS:\n",
    "      X - Input DataFrame (assumes Nx2 for N data points and 2 features)\n",
    "      featname_1, featname_2 - String containing feature names\n",
    "      model - Fitted LogisticRegressionCV model\n",
    "      \n",
    "    OUTPUTS:\n",
    "      ax - Returns figure axis object\n",
    "    '''\n",
    "    \n",
    "    # make grid\n",
    "    x_min, x_max = X[featname_1].min() - 0.5*X[featname_1].std(), X[featname_1].max() + 0.5*X[featname_1].std()\n",
    "    y_min, y_max = X[featname_2].min() - 0.5*X[featname_2].std(), X[featname_2].max() + 0.5*X[featname_2].std()\n",
    "    h = 0.02  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    #plt.figure(1, figsize=(4, 3))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Plot also the training points\n",
    "    #plt.scatter(X_train[features[i]][ Y_train == 0 ], X_train[features[j]][ Y_train == 0 ], c='r')\n",
    "    #plt.scatter(X_train[features[i]][ Y_train == 1 ], X_train[features[j]][ Y_train == 1 ], c='g')\n",
    "    #plt.scatter(X_train[features[i]][ Y_train == 2 ], X_train[features[j]][ Y_train == 2 ], c='b')\n",
    "\n",
    "    ax.scatter(X[featname_1][ y == 0 ], X[featname_2][ y == 0 ], c='r')\n",
    "    ax.scatter(X[featname_1][ y == 1 ], X[featname_2][ y == 1 ], c='g')\n",
    "    ax.scatter(X[featname_1][ y == 2 ], X[featname_2][ y == 2 ], c='b')\n",
    "\n",
    "    ax.set_xlabel(featname_1)\n",
    "    ax.set_ylabel(featname_2)\n",
    "    \n",
    "\n",
    "    #plt.xlim(xx.min(), xx.max())\n",
    "    #plt.ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a30859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced0bc3",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de803f23",
   "metadata": {},
   "source": [
    "### (c)  Training on Full Feature Set ( 10 points )\n",
    "\n",
    "Surprisingly, adding pairs of features doesn't seem to improve things.  Let's try training on all features.  In the cells below:\n",
    "* Perform 5-fold cross validation (using all the same parameters as before) to train a logistic regression classifier on all features\n",
    "* Report the maximum of the average scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef03b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90121175",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_of_avg=100 # your solution\n",
    "print(f\"The maximum of average scores is {max_of_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752c86a",
   "metadata": {},
   "source": [
    "If your results are the same as mine, the maximum score over all features is the same as over the best single feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3c23b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c0671",
   "metadata": {},
   "source": [
    "## Problem 3 : Support Vector Machine (10 points)\n",
    "\n",
    "We have trained several logistic regression classifiers, all of which achieve an a cross-validation accuracy well into the 90% range.  In an effort to see if we can do better, let's train one lass classifier--a support vector machine.  For this classifier we will introduce a nonlinear tranformation using the Radial Basis kernel function.  In the cell be low do the following:\n",
    "* Using Numpy.logspace create a logarithmically spaced set of 100 regularization coefficient in the range (1e-4, 1e4) \n",
    "* For each coefficient define a support vector classifier with kernel='rbf' and set the regularization coefficient (C=coefficient)\n",
    "* Perform 5-fold cross validation (e.g. using cross_val_score)\n",
    "* Plot the average accuracy versus regularization coefficient and report the maximum accuracy and best coefficient\n",
    "* Make sure to set the plot X-scale to 'log' and label axes and title\n",
    "\n",
    "[ Documentation - Scikit-Learn - svm.SVC ](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to generate Regularization Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and Train Models Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_avg_acc = 100 # Replace with your solution\n",
    "best_reg_coeff = 100 # Replace with your solution\n",
    "print(f\"The maximum average accuracy is {max_avg_acc}.\\nThe corresponding best regularization coefficient is {best_reg_coeff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b8077",
   "metadata": {},
   "source": [
    "My results show slightly higher accuracy under the SVM classifier.  However, cross_val_score does not use the same cross validation splits as the built-in cross validation of LogisticRegressionCV (which randomizes splits).  So we shall see..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680d37a",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81c5c2",
   "metadata": {},
   "source": [
    "## Problem 4 : Evaluate on test (10 points)\n",
    "\n",
    "Now we will evaluate all classifiers on the test data.  Take the best regression classifier and the best SVM classifier (with previously chosen parameters), train them, and evaluate accordingly.  For each classifier report:\n",
    "  * Test accuracy\n",
    "  * Confusion matrix\n",
    "  * Results of classification_report\n",
    "  \n",
    "We have only left a single cell below.  Feel free to insert additional cells and arrange output as you see fit.  Make sure it is readable.  Feel free to explore any additional visualizations or metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e783c61",
   "metadata": {},
   "source": [
    "#### Best Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66297f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135016b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to evaluate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2806d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594be3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ConfusionMatrixDisplay to display your confusion matrix : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to show classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa039ca0",
   "metadata": {},
   "source": [
    "#### Best SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74878fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25046a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to evaluate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM Classifier:\")\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ConfusionMatrixDisplay to display your confusion matrix : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code to show classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5704f4f8",
   "metadata": {},
   "source": [
    "The better classifier is {insert your answer} because {insert your answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5db634",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16c819",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    " As a last step before you submit, Please restart the notebook, rerun all cells, save and then submit.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
